{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20356d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb8e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f666c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "conf = OmegaConf.load('mles_params.yaml')\n",
    "model = hydra.utils.instantiate(conf.pl_module)\n",
    "model.load_state_dict(torch.load(\"models_alpha_battle/coles_pretrain.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c117b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
    "from ptls.data_load.iterable_processing.target_move import TargetMove\n",
    "from ptls.data_load.iterable_processing.target_empty_filter import TargetEmptyFilter\n",
    "from ptls.data_load import padded_collate, padded_collate_wo_target\n",
    "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ptls.data_load import IterableChain\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.data_load.datasets.parquet_dataset import ParquetDataset, ParquetFiles\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "\n",
    "\n",
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "train_data = glob('train_data_not_agg.parquet')\n",
    "valid_data = glob('valid_data_not_agg.parquet')\n",
    "\n",
    "feature_cols = ['mcc', 'amnt', 'hour_diff']\n",
    "\n",
    "target_cols = ['mcc', 'amnt', 'hour_diff']\n",
    "\n",
    "dataset_conf = {\n",
    "    'min_seq_len':0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class SeqToTargetMultiheadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 feature_cols,\n",
    "                 target_cols,\n",
    "                 target_dtype=None,\n",
    "                 *args, **kwargs,\n",
    "                 ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.data = data\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_cols = target_cols\n",
    "        \n",
    "        if type(target_dtype) is str:\n",
    "            self.target_dtype = getattr(torch, target_dtype)\n",
    "        else:\n",
    "            self.target_dtype = target_dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        feature_arrays = self.data[item]\n",
    "        return feature_arrays\n",
    "\n",
    "    def __iter__(self):\n",
    "        for feature_arrays in self.data:\n",
    "            yield feature_arrays\n",
    "\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \n",
    "        targets = []\n",
    "        values = []\n",
    "        \n",
    "        for target_col in target_cols:\n",
    "            targets.append(torch.tensor([rec[target_col][-1] for rec in batch]).to(self.target_dtype[target_col]))\n",
    "        \n",
    "        for rec in batch:\n",
    "            values.append({k: v[:-1] for k, v in rec.items() if k in feature_cols})\n",
    "    \n",
    "        return padded_collate_wo_target(values), targets\n",
    "\n",
    "process = IterableChain(\n",
    "            SeqLenFilter(min_seq_len=dataset_conf['min_seq_len']),\n",
    "            ToTorch()\n",
    "            )\n",
    "    \n",
    "def get_dataset(data):\n",
    "    ds = MemoryMapDataset(ParquetDataset(data, post_processing=process))\n",
    "    return SeqToTargetMultiheadDataset(ds, feature_cols, target_cols, target_dtype = {'mcc': torch.long, 'amnt': torch.float, 'hour_diff': torch.float})\n",
    "\n",
    "train_ds = get_dataset(train_data)\n",
    "valid_ds = get_dataset(valid_data)\n",
    "\n",
    "dm = PtlsDataModule(\n",
    "    train_data=train_ds,\n",
    "#     valid_data=valid_ds,\n",
    "    train_num_workers=4,\n",
    "    train_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6369addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from copy import deepcopy\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchmetrics\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class SequenceToTargetMultihead(pl.LightningModule):\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 seq_encoder: torch.nn.Module,\n",
    "                 heads: List[torch.nn.Module],\n",
    "                 losses: List[torch.nn.Module],\n",
    "                 metric_list: torchmetrics.Metric=None,\n",
    "                 optimizer_partial=None,\n",
    "                 lr_scheduler_partial=None,\n",
    "                 pretrained_lr=None,\n",
    "                 train_update_n_steps=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\n",
    "            'seq_encoder', 'heads', 'losses', 'metric_list', 'optimizer_partial', 'lr_scheduler_partial'])\n",
    "\n",
    "        self.seq_encoder = seq_encoder\n",
    "        self.heads = heads\n",
    "        self.losses = losses\n",
    "        self.n_heads = len(heads)\n",
    "\n",
    "        self.optimizer_partial = optimizer_partial\n",
    "        self.lr_scheduler_partial = lr_scheduler_partial\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq_encoder(x)\n",
    "        xs = [head(x) for head in self.heads]\n",
    "        return xs\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        y_hs = self(x)\n",
    "        loss = sum([loss(y_hs[i], y[i]) for i, loss in enumerate(self.losses)])\n",
    "        self.log('loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        y_hs = self(x)\n",
    "        loss = sum([loss(y_hs[i], y[i]) for i, loss in enumerate(self.losses)])\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.pretrained_lr is not None:\n",
    "            if self.hparams.pretrained_lr == 'freeze':\n",
    "                for p in self.seq_encoder.parameters():\n",
    "                    p.requires_grad = False\n",
    "                parameters = self.parameters()\n",
    "            else:\n",
    "                parameters = [\n",
    "                    {'params': self.seq_encoder.parameters(), 'lr': self.hparams.pretrained_lr},\n",
    "                ] + [{'params': head.parameters()} for head in self.heads]\n",
    "        else:\n",
    "            parameters = self.parameters()\n",
    "\n",
    "        optimizer = self.optimizer_partial(parameters)\n",
    "        scheduler = self.lr_scheduler_partial(optimizer)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12d1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.nn import Head\n",
    "\n",
    "\n",
    "head_mcc = Head(input_size=model.seq_encoder.embedding_size, \n",
    "                use_batch_norm=True,\n",
    "                hidden_layers_sizes=[128],\n",
    "                objective='classification',\n",
    "                num_classes=109).to('cuda:0')\n",
    "\n",
    "head_amnt = Head(input_size=model.seq_encoder.embedding_size, \n",
    "                 use_batch_norm=True,\n",
    "                 hidden_layers_sizes=[128],\n",
    "                 objective='softplus').to('cuda:0')\n",
    "\n",
    "head_hour_diff = Head(input_size=model.seq_encoder.embedding_size, \n",
    "                      use_batch_norm=True,\n",
    "                      hidden_layers_sizes=[128],\n",
    "                      objective='softplus').to('cuda:0')\n",
    "\n",
    "model_multihead = SequenceToTargetMultihead(\n",
    "    seq_encoder=model.seq_encoder,\n",
    "    heads=[head_mcc, head_amnt, head_hour_diff],\n",
    "    losses=[torch.nn.NLLLoss(), torch.nn.L1Loss(), torch.nn.L1Loss()],\n",
    "#     metric_list=torchmetrics.Accuracy(compute_on_step=False),\n",
    "    pretrained_lr=0.00001,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001), # , weight_decay=1e-5\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=1, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba1701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf82549fcdd04e488aaa61679022ee50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = TensorBoardLogger('src/ptls-experiments/scenario_alpha_battle/lightning_logs',\n",
    "                           name='coles-baseline-alpha-battle')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    num_sanity_val_steps=0,\n",
    "    gpus=1,\n",
    "    auto_select_gpus=False,\n",
    "    max_epochs=10,\n",
    "    enable_checkpointing=False,\n",
    "    deterministic=True,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model_multihead, dm)\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "560ea907",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_multihead.state_dict(), \"models_alpha_battle/cpc-multi-head.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef7d4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multihead.load_state_dict(torch.load(\"models_alpha_battle/cpc-multi-head.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90c5dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "import tqdm\n",
    "\n",
    "def inference(model, dl, device='cuda:0'):\n",
    "    \n",
    "    model.to(device)\n",
    "    X = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            features = batch[0]\n",
    "            targets = [t.unsqueeze(dim=1).to(device) for t in batch[1]]\n",
    "            x = model(features.to(device))\n",
    "            mcc = torch.argmax(x[0], dim=1, keepdim=True)\n",
    "            amnt = x[1].unsqueeze(dim=1)\n",
    "            hour_diff = x[2].unsqueeze(dim=1)\n",
    "            predicted = [mcc, amnt, hour_diff]\n",
    "            X += [torch.cat(predicted + targets, dim=1)]\n",
    "    return X\n",
    "\n",
    "\n",
    "valid_dl = torch.utils.data.DataLoader(dataset=valid_ds, \n",
    "                                       collate_fn=valid_ds.collate_fn,\n",
    "                                       num_workers=0,\n",
    "                                       batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc48408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3358/3358 [00:48<00:00, 68.73it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = torch.vstack(inference(model_multihead, valid_dl)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f1fe05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_mcc</th>\n",
       "      <th>predicted_amnt</th>\n",
       "      <th>predicted_hour_diff</th>\n",
       "      <th>mcc</th>\n",
       "      <th>amnt</th>\n",
       "      <th>hour_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.431450</td>\n",
       "      <td>28.729313</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.352101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.309665</td>\n",
       "      <td>23.632116</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.539584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.304868</td>\n",
       "      <td>13.139742</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.232139</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.308173</td>\n",
       "      <td>5.654250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.352706</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.350544</td>\n",
       "      <td>4.952467</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.477476</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_mcc  predicted_amnt  predicted_hour_diff   mcc      amnt  \\\n",
       "0            2.0        0.431450            28.729313   9.0  0.352101   \n",
       "1            1.0        0.309665            23.632116   2.0  0.539584   \n",
       "2           61.0        0.304868            13.139742  61.0  0.232139   \n",
       "3            1.0        0.308173             5.654250   1.0  0.352706   \n",
       "4            5.0        0.350544             4.952467   2.0  0.477476   \n",
       "\n",
       "   hour_diff  \n",
       "0        0.0  \n",
       "1        5.0  \n",
       "2        0.0  \n",
       "3       96.0  \n",
       "4      258.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_valid = pd.DataFrame(preds, columns = ['predicted_mcc', 'predicted_amnt', 'predicted_hour_diff', 'mcc', 'amnt', 'hour_diff'])\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abf71601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {0.3485738089087782}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", {accuracy_score(df_valid['mcc'],  df_valid['predicted_mcc'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c19b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mae amnt: {0.0768877}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"Mae amnt:\", {mean_absolute_error(df_valid['amnt'],  df_valid['predicted_amnt'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4d99d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: {41.097492}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE:\", {mean_absolute_error(df_valid['hour_diff'],  df_valid['predicted_hour_diff'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb3640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
