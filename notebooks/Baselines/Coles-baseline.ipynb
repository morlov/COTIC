{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c30036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ptls\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from ptls.frames import PtlsDataModule, coles\n",
    "from ptls.frames.coles import split_strategy\n",
    "from ptls.data_load import datasets\n",
    "from ptls.data_load.datasets import ParquetFiles\n",
    "from ptls.data_load.datasets import MemoryMapDataset, parquet_file_scan, ParquetDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.nn.trx_encoder import TrxEncoder\n",
    "from ptls.nn.seq_encoder import RnnSeqEncoder\n",
    "from ptls.nn.head import Head\n",
    "from ptls.frames.coles.losses import ContrastiveLoss\n",
    "from ptls.frames.coles import sampling_strategies\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6811f",
   "metadata": {},
   "source": [
    "# <font size=\"7\">Data Module</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00688527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.frames import coles\n",
    "from ptls.data_load import datasets\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.coles import losses, sampling_strategies\n",
    "from ptls.frames.coles import split_strategy\n",
    "\n",
    "data_module = PtlsDataModule(\n",
    "    train_data=ptls.frames.coles.ColesDataset(\n",
    "        splitter=split_strategy.SampleSlices(split_count=5, cnt_min=20, cnt_max=60),\n",
    "        data=ptls.data_load.datasets.AugmentationDataset(\n",
    "            data=MemoryMapDataset(\n",
    "                data=ParquetDataset(\n",
    "                    i_filters=[SeqLenFilter(min_seq_len=30), FeatureFilter()],\n",
    "                    data_files=parquet_file_scan(file_path='train_df_agg.parquet',\n",
    "                                                 valid_rate=0,\n",
    "                                                 return_part='train')\n",
    "                )\n",
    "            ),\n",
    "            f_augmentations=[ptls.data_load.augmentations.DropoutTrx(trx_dropout=0.01)]\n",
    "        )\n",
    "    ),\n",
    "train_batch_size=256,\n",
    "train_num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786f71f",
   "metadata": {},
   "source": [
    "# <font size=\"7\">Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cabebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoLESModule(\n",
    "      validation_metric=ptls.frames.coles.metric.BatchRecallTopK(K=4,\n",
    "                                                                 metric=\"cosine\"),\n",
    "      seq_encoder=RnnSeqEncoder(\n",
    "            trx_encoder=TrxEncoder(\n",
    "            use_batch_norm_with_lens=True,\n",
    "            norm_embeddings=False,\n",
    "            embeddings_noise=0.003,\n",
    "            \n",
    "            embeddings={\n",
    "                \"mcc\": {\"in\": 110, \"out\": 32},\n",
    "            },\n",
    "\n",
    "            numeric_values={\n",
    "                'amnt': 'identity',\n",
    "                'hour_diff': 'identity',\n",
    "            },\n",
    "            ),\n",
    "            type=\"lstm\",\n",
    "            hidden_size=1024,\n",
    "            bidir=False,\n",
    "            trainable_starter=\"static\",\n",
    "      ),\n",
    "     \n",
    "      head=Head(\n",
    "            use_norm_encoder=False,\n",
    "            input_size=1024,\n",
    "      ),\n",
    "\n",
    "      loss=ContrastiveLoss(\n",
    "            margin=0.5,\n",
    "            sampling_strategy=sampling_strategies.HardNegativePairSelector(neg_count=5),\n",
    "      ),\n",
    "    \n",
    "      optimizer_partial=partial(\n",
    "            torch.optim.Adam, \n",
    "            lr=0.001,\n",
    "            weight_decay=0.0\n",
    "      ),\n",
    "    \n",
    "      lr_scheduler_partial=partial(\n",
    "            torch.optim.lr_scheduler.StepLR,\n",
    "            step_size=1,\n",
    "            gamma=0.8,\n",
    "      ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852639a",
   "metadata": {},
   "source": [
    "# <font size=\"7\">Fitting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    num_sanity_val_steps=0,\n",
    "    gpus=1,\n",
    "    auto_select_gpus=False,\n",
    "    max_epochs=30,\n",
    "    enable_checkpointing=False,\n",
    "    deterministic=True\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c909c6",
   "metadata": {},
   "source": [
    "# <font size=\"5\">Load trained model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb346331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'path/model.pth'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061bcdbc",
   "metadata": {},
   "source": [
    "# <font size=\"7\">Inference</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e68545",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('data/train.parquet').drop(columns=['transaction_number',\n",
    "                                                               'reversed_transaction', \n",
    "                                                               'transaction_max',\n",
    "                                                               'time'])\n",
    "\n",
    "valid_df = pd.read_parquet('data/valid.parquet').drop(columns=['transaction_number',\n",
    "                                                               'reversed_transaction', \n",
    "                                                               'transaction_max',\n",
    "                                                               'time'])\n",
    "last_transactions_train = train_df.groupby('app_id').tail(1)\n",
    "\n",
    "first_transactions_valid = valid_df.groupby('app_id').head(1)\n",
    "first_transactions_valid = first_transactions_valid.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa8db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0b0592d7ec427c853424ad03eba31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "iterable_inference_dataset = ParquetDataset(\n",
    "    data_files=ParquetFiles(['train_agg_inference.parquet'],                                                                   \n",
    "                            ).data_files\n",
    ")\n",
    "\n",
    "next(iter(iterable_inference_dataset))\n",
    "\n",
    "inference_dl = torch.utils.data.DataLoader(\n",
    "    dataset=iterable_inference_dataset,\n",
    "    collate_fn=collate_feature_dict,\n",
    "    shuffle=False,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "next(iter(inference_dl)).payload\n",
    "\n",
    "mod = InferenceModule(model, pandas_output=True, model_out_name='emb')\n",
    "\n",
    "pred = pl.Trainer(gpus=1).predict(mod, inference_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc41c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>emb_0000</th>\n",
       "      <th>emb_0001</th>\n",
       "      <th>emb_0002</th>\n",
       "      <th>emb_0003</th>\n",
       "      <th>emb_0004</th>\n",
       "      <th>emb_0005</th>\n",
       "      <th>emb_0006</th>\n",
       "      <th>emb_0007</th>\n",
       "      <th>emb_0008</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_1014</th>\n",
       "      <th>emb_1015</th>\n",
       "      <th>emb_1016</th>\n",
       "      <th>emb_1017</th>\n",
       "      <th>emb_1018</th>\n",
       "      <th>emb_1019</th>\n",
       "      <th>emb_1020</th>\n",
       "      <th>emb_1021</th>\n",
       "      <th>emb_1022</th>\n",
       "      <th>emb_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>-0.014253</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.004606</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>-0.240523</td>\n",
       "      <td>0.172152</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>-0.029905</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>-0.007254</td>\n",
       "      <td>-0.922810</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>-0.015699</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.006467</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>-0.208373</td>\n",
       "      <td>0.165709</td>\n",
       "      <td>0.014849</td>\n",
       "      <td>-0.025442</td>\n",
       "      <td>-0.001140</td>\n",
       "      <td>-0.008975</td>\n",
       "      <td>-0.922521</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>-0.013657</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>0.013092</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.005264</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>-0.253237</td>\n",
       "      <td>0.166377</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>-0.053596</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.009352</td>\n",
       "      <td>-0.926340</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>-0.010952</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>-0.011730</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.228056</td>\n",
       "      <td>0.163205</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>-0.038170</td>\n",
       "      <td>-0.001332</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>-0.925197</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>-0.015211</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.234176</td>\n",
       "      <td>0.166675</td>\n",
       "      <td>0.025411</td>\n",
       "      <td>-0.043626</td>\n",
       "      <td>-0.001973</td>\n",
       "      <td>-0.008154</td>\n",
       "      <td>-0.922646</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1003041</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>-0.011157</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.007234</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>-0.229039</td>\n",
       "      <td>0.165724</td>\n",
       "      <td>0.018091</td>\n",
       "      <td>-0.052470</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.009233</td>\n",
       "      <td>-0.929722</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1003044</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.010082</td>\n",
       "      <td>-0.012899</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.012460</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.007317</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.204652</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.020121</td>\n",
       "      <td>-0.045413</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>-0.008040</td>\n",
       "      <td>-0.928399</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1003047</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>-0.016791</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.234429</td>\n",
       "      <td>0.175132</td>\n",
       "      <td>0.031866</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.009457</td>\n",
       "      <td>-0.931182</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1003048</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>-0.011837</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.011703</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.241328</td>\n",
       "      <td>0.162514</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>-0.061186</td>\n",
       "      <td>-0.012767</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>-0.930808</td>\n",
       "      <td>0.000540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1003049</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>-0.012642</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.014150</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>-0.210552</td>\n",
       "      <td>0.146074</td>\n",
       "      <td>0.011137</td>\n",
       "      <td>-0.050848</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.007053</td>\n",
       "      <td>-0.922831</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430309 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id  emb_0000  emb_0001  emb_0002  emb_0003  emb_0004  emb_0005  \\\n",
       "0          0  0.003914  0.009090 -0.014253 -0.000246  0.012538  0.000039   \n",
       "1          1  0.004588  0.008645 -0.015699 -0.000383  0.012169  0.000302   \n",
       "2          2  0.003725  0.009859 -0.013657 -0.000366  0.013092  0.000565   \n",
       "3          4  0.003516  0.008183 -0.010952 -0.000286  0.013063  0.000955   \n",
       "4          6  0.003416  0.012006 -0.015211 -0.000311  0.014764  0.000380   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "96   1003041  0.003916  0.007977 -0.011157 -0.000312  0.010694 -0.000223   \n",
       "97   1003044  0.003665  0.010082 -0.012899 -0.000328  0.012460  0.000326   \n",
       "98   1003047  0.002183  0.012965 -0.016791 -0.000241  0.015602  0.000425   \n",
       "99   1003048  0.002896  0.007967 -0.011837 -0.000284  0.014049  0.000088   \n",
       "100  1003049  0.003950  0.007321 -0.012642 -0.000423  0.009730  0.000942   \n",
       "\n",
       "     emb_0006  emb_0007  emb_0008  ...  emb_1014  emb_1015  emb_1016  \\\n",
       "0    0.000037 -0.004606  0.002772  ... -0.000033 -0.000383 -0.240523   \n",
       "1    0.000100 -0.006467  0.002386  ... -0.000029 -0.000440 -0.208373   \n",
       "2    0.000033 -0.005264  0.002802  ... -0.000011 -0.000551 -0.253237   \n",
       "3    0.000108 -0.011730  0.002057  ... -0.000061 -0.000149 -0.228056   \n",
       "4    0.000117 -0.004704  0.003123  ... -0.000035 -0.000401 -0.234176   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "96   0.000299 -0.007234  0.002428  ... -0.000009 -0.000503 -0.229039   \n",
       "97   0.000084 -0.007317  0.003034  ... -0.000016 -0.000322 -0.204652   \n",
       "98   0.000013  0.021656  0.002620  ... -0.000019 -0.000109 -0.234429   \n",
       "99   0.000073 -0.011703  0.002389  ... -0.000007 -0.000069 -0.241328   \n",
       "100  0.000052 -0.014150  0.002398  ...  0.000002 -0.000454 -0.210552   \n",
       "\n",
       "     emb_1017  emb_1018  emb_1019  emb_1020  emb_1021  emb_1022  emb_1023  \n",
       "0    0.172152  0.013610 -0.029905 -0.000650 -0.007254 -0.922810  0.000551  \n",
       "1    0.165709  0.014849 -0.025442 -0.001140 -0.008975 -0.922521  0.000288  \n",
       "2    0.166377  0.014257 -0.053596  0.001399 -0.009352 -0.926340  0.000173  \n",
       "3    0.163205  0.017917 -0.038170 -0.001332 -0.006900 -0.925197  0.000135  \n",
       "4    0.166675  0.025411 -0.043626 -0.001973 -0.008154 -0.922646  0.000166  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "96   0.165724  0.018091 -0.052470 -0.000024 -0.009233 -0.929722  0.000126  \n",
       "97   0.158848  0.020121 -0.045413  0.000224 -0.008040 -0.928399  0.000227  \n",
       "98   0.175132  0.031866 -0.067642  0.000083 -0.009457 -0.931182  0.000038  \n",
       "99   0.162514  0.033378 -0.061186 -0.012767 -0.008983 -0.930808  0.000540  \n",
       "100  0.146074  0.011137 -0.050848  0.000156 -0.007053 -0.922831  0.000385  \n",
       "\n",
       "[430309 rows x 1025 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings = pd.concat(pred, axis=0)\n",
    "train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab577508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.imgenv-test-4-0/lib/python3.7/site-packages/pytorch_lightning/loops/utilities.py:95: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  category=PossibleUserWarning,\n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jovyan/.imgenv-test-4-0/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ee021046fc484facbbcca02c567cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "iterable_inference_dataset = ParquetDataset(\n",
    "    data_files=ParquetFiles(['train_agg_with_last.parquet'],                                                                   \n",
    "                            ).data_files\n",
    ")\n",
    "\n",
    "next(iter(iterable_inference_dataset))\n",
    "\n",
    "inference_dl = torch.utils.data.DataLoader(\n",
    "    dataset=iterable_inference_dataset,\n",
    "    collate_fn=collate_feature_dict,\n",
    "    shuffle=False,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "next(iter(inference_dl)).payload\n",
    "\n",
    "mod = InferenceModule(model, pandas_output=True, model_out_name='emb')\n",
    "\n",
    "pred = pl.Trainer(gpus=1).predict(mod, inference_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af88d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>emb_0000</th>\n",
       "      <th>emb_0001</th>\n",
       "      <th>emb_0002</th>\n",
       "      <th>emb_0003</th>\n",
       "      <th>emb_0004</th>\n",
       "      <th>emb_0005</th>\n",
       "      <th>emb_0006</th>\n",
       "      <th>emb_0007</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_1014</th>\n",
       "      <th>emb_1015</th>\n",
       "      <th>emb_1016</th>\n",
       "      <th>emb_1017</th>\n",
       "      <th>emb_1018</th>\n",
       "      <th>emb_1019</th>\n",
       "      <th>emb_1020</th>\n",
       "      <th>emb_1021</th>\n",
       "      <th>emb_1022</th>\n",
       "      <th>emb_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>-0.014293</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>0.012551</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.004674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>-0.240582</td>\n",
       "      <td>0.172266</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>-0.030062</td>\n",
       "      <td>-6.748151e-04</td>\n",
       "      <td>-0.007260</td>\n",
       "      <td>-0.922807</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>-0.015979</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>-0.005672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.208511</td>\n",
       "      <td>0.165530</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>-0.025615</td>\n",
       "      <td>-8.217460e-04</td>\n",
       "      <td>-0.008998</td>\n",
       "      <td>-0.922640</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>-0.013814</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.013076</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>-0.253382</td>\n",
       "      <td>0.166213</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>-0.053099</td>\n",
       "      <td>1.477676e-03</td>\n",
       "      <td>-0.009166</td>\n",
       "      <td>-0.926000</td>\n",
       "      <td>0.000461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>-0.011009</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.011767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000471</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>0.162135</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>-0.038361</td>\n",
       "      <td>-1.473200e-03</td>\n",
       "      <td>-0.007030</td>\n",
       "      <td>-0.925887</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>-0.015138</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.005414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.233494</td>\n",
       "      <td>0.166833</td>\n",
       "      <td>0.025795</td>\n",
       "      <td>-0.044710</td>\n",
       "      <td>-1.900411e-03</td>\n",
       "      <td>-0.008051</td>\n",
       "      <td>-0.923124</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1003041</td>\n",
       "      <td>1003041</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>-0.011141</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>0.010702</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.006615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.228219</td>\n",
       "      <td>0.165549</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>-0.052359</td>\n",
       "      <td>4.598223e-05</td>\n",
       "      <td>-0.009202</td>\n",
       "      <td>-0.929624</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1003044</td>\n",
       "      <td>1003044</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>-0.012860</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-0.007098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.203613</td>\n",
       "      <td>0.158468</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>-0.045447</td>\n",
       "      <td>2.339469e-04</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>-0.928267</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1003047</td>\n",
       "      <td>1003047</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>-0.016875</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.234061</td>\n",
       "      <td>0.175686</td>\n",
       "      <td>0.031994</td>\n",
       "      <td>-0.067409</td>\n",
       "      <td>1.178113e-03</td>\n",
       "      <td>-0.009536</td>\n",
       "      <td>-0.930796</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1003048</td>\n",
       "      <td>1003048</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.011217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.241808</td>\n",
       "      <td>0.162941</td>\n",
       "      <td>0.033595</td>\n",
       "      <td>-0.061391</td>\n",
       "      <td>-1.190810e-02</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.930358</td>\n",
       "      <td>0.000499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1003049</td>\n",
       "      <td>1003049</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>-0.012677</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.014346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>-0.210020</td>\n",
       "      <td>0.145817</td>\n",
       "      <td>0.011223</td>\n",
       "      <td>-0.050871</td>\n",
       "      <td>-5.926662e-07</td>\n",
       "      <td>-0.006986</td>\n",
       "      <td>-0.922821</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429711 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id  __index_level_0__  emb_0000  emb_0001  emb_0002  emb_0003  \\\n",
       "0         0                  0  0.003954  0.009111 -0.014293 -0.000325   \n",
       "1         1                  1  0.004714  0.008807 -0.015979 -0.000310   \n",
       "2         2                  2  0.003796  0.009738 -0.013814 -0.000293   \n",
       "3         4                  4  0.003309  0.008386 -0.011009 -0.000180   \n",
       "4         6                  6  0.003716  0.011732 -0.015138 -0.000223   \n",
       "..      ...                ...       ...       ...       ...       ...   \n",
       "10  1003041            1003041  0.003914  0.007778 -0.011141 -0.000428   \n",
       "11  1003044            1003044  0.003618  0.010039 -0.012860 -0.000389   \n",
       "12  1003047            1003047  0.002288  0.012747 -0.016875 -0.000248   \n",
       "13  1003048            1003048  0.002844  0.008093 -0.012014 -0.000162   \n",
       "14  1003049            1003049  0.004004  0.007357 -0.012677 -0.000655   \n",
       "\n",
       "    emb_0004  emb_0005  emb_0006  emb_0007  ...  emb_1014  emb_1015  emb_1016  \\\n",
       "0   0.012551  0.000029  0.000038 -0.004674  ... -0.000020 -0.000435 -0.240582   \n",
       "1   0.012286  0.000031  0.000120 -0.005672  ... -0.000265 -0.000468 -0.208511   \n",
       "2   0.013076  0.000626  0.000028 -0.005176  ... -0.000014 -0.000696 -0.253382   \n",
       "3   0.013555  0.001056  0.000056 -0.011767  ... -0.000471 -0.000106 -0.231477   \n",
       "4   0.014705  0.000446  0.000113 -0.005414  ... -0.000041 -0.000651 -0.233494   \n",
       "..       ...       ...       ...       ...  ...       ...       ...       ...   \n",
       "10  0.010702 -0.000054  0.000274 -0.006615  ... -0.000008 -0.000311 -0.228219   \n",
       "11  0.012328  0.000290  0.000188 -0.007098  ... -0.000020 -0.000225 -0.203613   \n",
       "12  0.015567  0.000398  0.000014  0.020858  ... -0.000008 -0.000119 -0.234061   \n",
       "13  0.014526 -0.000348  0.000033 -0.011217  ... -0.000162 -0.000124 -0.241808   \n",
       "14  0.009733  0.000899  0.000055 -0.014346  ...  0.000011 -0.000519 -0.210020   \n",
       "\n",
       "    emb_1017  emb_1018  emb_1019      emb_1020  emb_1021  emb_1022  emb_1023  \n",
       "0   0.172266  0.013527 -0.030062 -6.748151e-04 -0.007260 -0.922807  0.000460  \n",
       "1   0.165530  0.014747 -0.025615 -8.217460e-04 -0.008998 -0.922640  0.000153  \n",
       "2   0.166213  0.014296 -0.053099  1.477676e-03 -0.009166 -0.926000  0.000461  \n",
       "3   0.162135  0.018395 -0.038361 -1.473200e-03 -0.007030 -0.925887  0.000223  \n",
       "4   0.166833  0.025795 -0.044710 -1.900411e-03 -0.008051 -0.923124  0.000108  \n",
       "..       ...       ...       ...           ...       ...       ...       ...  \n",
       "10  0.165549  0.017762 -0.052359  4.598223e-05 -0.009202 -0.929624  0.000142  \n",
       "11  0.158468  0.020052 -0.045447  2.339469e-04 -0.008030 -0.928267  0.000137  \n",
       "12  0.175686  0.031994 -0.067409  1.178113e-03 -0.009536 -0.930796  0.000089  \n",
       "13  0.162941  0.033595 -0.061391 -1.190810e-02 -0.008797 -0.930358  0.000499  \n",
       "14  0.145817  0.011223 -0.050871 -5.926662e-07 -0.006986 -0.922821  0.000178  \n",
       "\n",
       "[429711 rows x 1026 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings_with_last = pd.concat(pred, axis=0)\n",
    "train_embeddings_with_last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06749e",
   "metadata": {},
   "source": [
    "# <font size=\"5\">hour diff predicting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de27501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 32.3118480\ttotal: 25.9ms\tremaining: 51.9s\n",
      "100:\tlearn: 32.1403991\ttotal: 2.32s\tremaining: 43.7s\n",
      "200:\tlearn: 31.9894634\ttotal: 4.59s\tremaining: 41.1s\n",
      "300:\tlearn: 31.8592012\ttotal: 6.92s\tremaining: 39s\n",
      "400:\tlearn: 31.7512392\ttotal: 9.28s\tremaining: 37s\n",
      "500:\tlearn: 31.6641739\ttotal: 11.5s\tremaining: 34.5s\n",
      "600:\tlearn: 31.5934224\ttotal: 13.7s\tremaining: 32s\n",
      "700:\tlearn: 31.5360450\ttotal: 15.9s\tremaining: 29.5s\n",
      "800:\tlearn: 31.4888162\ttotal: 18s\tremaining: 27s\n",
      "900:\tlearn: 31.4492260\ttotal: 20.2s\tremaining: 24.6s\n",
      "1000:\tlearn: 31.4163264\ttotal: 22.2s\tremaining: 22.2s\n",
      "1100:\tlearn: 31.3884116\ttotal: 24.3s\tremaining: 19.8s\n",
      "1200:\tlearn: 31.3646775\ttotal: 26.3s\tremaining: 17.5s\n",
      "1300:\tlearn: 31.3435229\ttotal: 28.4s\tremaining: 15.2s\n",
      "1400:\tlearn: 31.3253127\ttotal: 30.4s\tremaining: 13s\n",
      "1500:\tlearn: 31.3091011\ttotal: 32.4s\tremaining: 10.8s\n",
      "1600:\tlearn: 31.2939562\ttotal: 34.4s\tremaining: 8.58s\n",
      "1700:\tlearn: 31.2803544\ttotal: 36.5s\tremaining: 6.41s\n",
      "1800:\tlearn: 31.2682770\ttotal: 38.5s\tremaining: 4.25s\n",
      "1900:\tlearn: 31.2571803\ttotal: 40.5s\tremaining: 2.11s\n",
      "1999:\tlearn: 31.2466483\ttotal: 42.5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f3422511dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_time = CatBoostRegressor(\n",
    "    learning_rate=1e-1,\n",
    "    iterations=2000,\n",
    "    depth=7,\n",
    "    verbose=100,\n",
    "    task_type='GPU',\n",
    "    loss_function='MAE',\n",
    "    eval_metric='MAE',\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n",
    "regressor_time.fit(train_embeddings,\n",
    "              last_transactions_train['hour_diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94aeb29",
   "metadata": {},
   "source": [
    "# <font size=\"5\">mcc predicting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c453101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3071072\ttotal: 341ms\tremaining: 2m 49s\n",
      "100:\tlearn: 0.3460211\ttotal: 31.7s\tremaining: 2m 5s\n",
      "200:\tlearn: 0.3548380\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "300:\tlearn: 0.3580264\ttotal: 1m 33s\tremaining: 1m 1s\n",
      "400:\tlearn: 0.3605223\ttotal: 2m 3s\tremaining: 30.5s\n",
      "499:\tlearn: 0.3623350\ttotal: 2m 33s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f30ebc06610>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_mcc = CatBoostClassifier(\n",
    "    learning_rate=1e-1,\n",
    "    iterations=500,\n",
    "    depth=3,\n",
    "    verbose=100,\n",
    "    task_type='GPU',\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n",
    "classifier_mcc.fit(train_embeddings,\n",
    "              last_transactions_train['mcc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a9f18",
   "metadata": {},
   "source": [
    "# <font size=\"5\">amount predicting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97aef98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5714057\ttotal: 31.1ms\tremaining: 15.5s\n",
      "100:\tlearn: 0.5836016\ttotal: 2.06s\tremaining: 8.13s\n",
      "200:\tlearn: 0.5853422\ttotal: 4.04s\tremaining: 6.01s\n",
      "300:\tlearn: 0.5865576\ttotal: 5.97s\tremaining: 3.95s\n",
      "400:\tlearn: 0.5881192\ttotal: 7.9s\tremaining: 1.95s\n",
      "499:\tlearn: 0.5892161\ttotal: 9.78s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f30ebc06dd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_amnt = CatBoostClassifier(\n",
    "    learning_rate=1e-1,\n",
    "    iterations=500,\n",
    "    depth=5,\n",
    "    verbose=100,\n",
    "    task_type='GPU',\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n",
    "classifier_amnt.fit(train_embeddings,\n",
    "              last_transactions_train['amnt_bins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9835720",
   "metadata": {},
   "source": [
    "# <font size=\"6\">Metrics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85876b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time MAE: 30.59788261215277\n",
      "Mcc Accuracy 0.3567886323598884\n",
      "Amnt Accuracy 0.5833059893742538\n"
     ]
    }
   ],
   "source": [
    "preds = regressor_time.predict(train_embeddings_with_last.drop(columns='app_id'))\n",
    "\n",
    "print('Time MAE:', mean_absolute_error(first_transactions_valid['hour_diff'], preds))\n",
    "\n",
    "preds = classifier_mcc.predict(train_embeddings_with_last)\n",
    "\n",
    "print('Mcc Accuracy', accuracy_score(first_transactions_valid['mcc'], preds))\n",
    "\n",
    "preds = classifier_amnt.predict(train_embeddings_with_last)\n",
    "\n",
    "print('Amnt Accuracy', accuracy_score(first_transactions_valid['amnt_bins'], preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
